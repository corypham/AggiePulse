{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/corypham/AggiePulse/blob/main/process_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWXVmcQbHsVl"
      },
      "source": [
        "# Post Processing for Tennis Court & Ball Detection\n",
        "\n",
        "This notebook leverages Google Colab's online GPUs for CourtCheck's post processing. Pretrained weights are referenced in the **last cell** for both Court and Ball detection models. Please run each cell **chronologically** and change your input & output paths in **mp4 format**. For any questions, please contact corypham1@gmail.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE0G1Vz4h5wj",
        "outputId": "6670f14d-b22c-4a99-e1f9-f73ee41b258b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ssffwZ_8iXTY",
        "outputId": "e9a8ffca-f1bf-474a-a248-dc6df5c75e38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m116.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting scenedetect\n",
            "  Downloading scenedetect-0.6.5.2-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: Click in /usr/local/lib/python3.11/dist-packages (from scenedetect) (8.1.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from scenedetect) (1.26.4)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from scenedetect) (4.3.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from scenedetect) (4.67.1)\n",
            "Downloading scenedetect-0.6.5.2-py3-none-any.whl (127 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.3/127.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scenedetect\n",
            "Successfully installed scenedetect-0.6.5.2\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (1.26.4)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement CubicSpline (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for CubicSpline\u001b[0m\u001b[31m\n",
            "\u001b[0mTrue\n"
          ]
        }
      ],
      "source": [
        "# Basic dependencies\n",
        "!pip install numpy opencv-python torch torchvision tqdm scipy matplotlib\n",
        "\n",
        "# Scene detection\n",
        "!pip install scenedetect\n",
        "\n",
        "# CatBoost for bounce detection\n",
        "!pip install catboost\n",
        "\n",
        "# For visualization\n",
        "!pip install opencv-python-headless\n",
        "\n",
        "!pip install CubicSpline\n",
        "\n",
        "# If you need CUDA support (usually pre-installed in Colab)\n",
        "import torch\n",
        "print(torch.cuda.is_available())  # Should print True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ug0j2wIt6C1"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import warnings\n",
        "import logging\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch\n",
        "import time\n",
        "from scipy.spatial import distance\n",
        "from itertools import groupby\n",
        "from tqdm import tqdm\n",
        "from collections import deque\n",
        "import catboost as ctb\n",
        "import pandas as pd\n",
        "import torch.nn.functional as F\n",
        "from scenedetect.video_manager import VideoManager\n",
        "from scenedetect.scene_manager import SceneManager\n",
        "from scenedetect.stats_manager import StatsManager\n",
        "from scenedetect.detectors import ContentDetector\n",
        "from scipy.interpolate import CubicSpline\n",
        "from sympy import Line\n",
        "from scipy.spatial import distance\n",
        "from scipy import signal\n",
        "import matplotlib.pyplot as plt\n",
        "from sympy.geometry.point import Point2D\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBGsridfrwE9"
      },
      "outputs": [],
      "source": [
        "## Tracknet script\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, pad=1, stride=1, bias=True):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=pad, bias=bias),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "class BallTrackerNet(nn.Module):\n",
        "    def __init__(self, input_channels=3, out_channels=14):\n",
        "        super().__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.input_channels = input_channels\n",
        "\n",
        "        self.conv1 = ConvBlock(in_channels=self.input_channels, out_channels=64)\n",
        "        self.conv2 = ConvBlock(in_channels=64, out_channels=64)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv3 = ConvBlock(in_channels=64, out_channels=128)\n",
        "        self.conv4 = ConvBlock(in_channels=128, out_channels=128)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv5 = ConvBlock(in_channels=128, out_channels=256)\n",
        "        self.conv6 = ConvBlock(in_channels=256, out_channels=256)\n",
        "        self.conv7 = ConvBlock(in_channels=256, out_channels=256)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv8 = ConvBlock(in_channels=256, out_channels=512)\n",
        "        self.conv9 = ConvBlock(in_channels=512, out_channels=512)\n",
        "        self.conv10 = ConvBlock(in_channels=512, out_channels=512)\n",
        "        self.ups1 = nn.Upsample(scale_factor=2)\n",
        "        self.conv11 = ConvBlock(in_channels=512, out_channels=256)\n",
        "        self.conv12 = ConvBlock(in_channels=256, out_channels=256)\n",
        "        self.conv13 = ConvBlock(in_channels=256, out_channels=256)\n",
        "        self.ups2 = nn.Upsample(scale_factor=2)\n",
        "        self.conv14 = ConvBlock(in_channels=256, out_channels=128)\n",
        "        self.conv15 = ConvBlock(in_channels=128, out_channels=128)\n",
        "        self.ups3 = nn.Upsample(scale_factor=2)\n",
        "        self.conv16 = ConvBlock(in_channels=128, out_channels=64)\n",
        "        self.conv17 = ConvBlock(in_channels=64, out_channels=64)\n",
        "        self.conv18 = ConvBlock(in_channels=64, out_channels=self.out_channels)\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.conv6(x)\n",
        "        x = self.conv7(x)\n",
        "        x = self.pool3(x)\n",
        "        x = self.conv8(x)\n",
        "        x = self.conv9(x)\n",
        "        x = self.conv10(x)\n",
        "        x = self.ups1(x)\n",
        "        x = self.conv11(x)\n",
        "        x = self.conv12(x)\n",
        "        x = self.conv13(x)\n",
        "        x = self.ups2(x)\n",
        "        x = self.conv14(x)\n",
        "        x = self.conv15(x)\n",
        "        x = self.ups3(x)\n",
        "        x = self.conv16(x)\n",
        "        x = self.conv17(x)\n",
        "        x = self.conv18(x)\n",
        "        return x\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.Conv2d):\n",
        "                nn.init.uniform_(module.weight, -0.05, 0.05)\n",
        "                if module.bias is not None:\n",
        "                    nn.init.constant_(module.bias, 0)\n",
        "\n",
        "            elif isinstance(module, nn.BatchNorm2d):\n",
        "                nn.init.constant_(module.weight, 1)\n",
        "                nn.init.constant_(module.bias, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxZNBGsMlAqf"
      },
      "outputs": [],
      "source": [
        "# Utility Script\n",
        "\n",
        "\n",
        "def scene_detect(path_video):\n",
        "    \"\"\"\n",
        "    Split video to disjoint fragments based on color histograms\n",
        "    using PySceneDetect.\n",
        "    \"\"\"\n",
        "    video_manager = VideoManager([path_video])\n",
        "    stats_manager = StatsManager()\n",
        "    scene_manager = SceneManager(stats_manager)\n",
        "    scene_manager.add_detector(ContentDetector())\n",
        "    base_timecode = video_manager.get_base_timecode()\n",
        "\n",
        "    video_manager.set_downscale_factor()\n",
        "    video_manager.start()\n",
        "    scene_manager.detect_scenes(frame_source=video_manager)\n",
        "    scene_list = scene_manager.get_scene_list(base_timecode)\n",
        "\n",
        "    if not scene_list:\n",
        "        scene_list = [\n",
        "            (video_manager.get_base_timecode(), video_manager.get_current_timecode())\n",
        "        ]\n",
        "    scenes = [[x[0].frame_num, x[1].frame_num] for x in scene_list]\n",
        "    return scenes\n",
        "\n",
        "\n",
        "def build_heatmap_court_background_black():\n",
        "    \"\"\"\n",
        "    Black background with thick white court lines.\n",
        "    \"\"\"\n",
        "    raw_court = CourtReference().build_court_reference()\n",
        "    raw_court = cv2.dilate(raw_court, np.ones((10, 10), dtype=np.uint8))\n",
        "\n",
        "    background = np.zeros_like(raw_court, dtype=np.uint8)\n",
        "    background[raw_court == 1] = 255  # white lines\n",
        "    return cv2.cvtColor(background, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "\n",
        "def build_custom_colormap_black_purple_red_green_yellow():\n",
        "    \"\"\"\n",
        "    Creates a custom color map (256 x 1 x 3) with 5 anchors:\n",
        "      0   -> black\n",
        "      64  -> purple\n",
        "      128 -> red\n",
        "      192 -> green\n",
        "      255 -> bright yellow\n",
        "    This ensures that 'no data' (0) stays black, and high frequency = yellow.\n",
        "    \"\"\"\n",
        "    anchors = [\n",
        "        (0, (0, 0, 0)),  # black\n",
        "        (64, (128, 0, 128)),  # purple\n",
        "        (128, (0, 0, 255)),  # red\n",
        "        (192, (0, 255, 0)),  # green\n",
        "        (255, (0, 255, 255)),  # bright yellow\n",
        "    ]\n",
        "    ctable = np.zeros((256, 1, 3), dtype=np.uint8)\n",
        "\n",
        "    def lerp_color(c1, c2, t):\n",
        "        return (\n",
        "            int(c1[0] + (c2[0] - c1[0]) * t),\n",
        "            int(c1[1] + (c2[1] - c1[1]) * t),\n",
        "            int(c1[2] + (c2[2] - c1[2]) * t),\n",
        "        )\n",
        "\n",
        "    for i in range(len(anchors) - 1):\n",
        "        start_idx, start_col = anchors[i]\n",
        "        end_idx, end_col = anchors[i + 1]\n",
        "        for x in range(start_idx, end_idx + 1):\n",
        "            if end_idx == start_idx:\n",
        "                t = 0\n",
        "            else:\n",
        "                t = (x - start_idx) / float(end_idx - start_idx)\n",
        "            ctable[x, 0] = lerp_color(start_col, end_col, t)\n",
        "\n",
        "    return ctable\n",
        "\n",
        "\n",
        "def generate_minimap_heatmaps(\n",
        "    homography_matrices,\n",
        "    ball_track,\n",
        "    bounces,\n",
        "    persons_top,\n",
        "    persons_bottom,\n",
        "    output_bounce_heatmap,\n",
        "    output_player_heatmap,\n",
        "    blur_ksize=41,\n",
        "    alpha=0.5,\n",
        "):\n",
        "    \"\"\"\n",
        "    1) For ball bounces, draw bigger bright‐yellow circles (radius=8) with red outline.\n",
        "    2) For player positions, accumulate + blur, then apply a custom colormap:\n",
        "       black->purple->red->green->yellow, so zero=black, max=yellow.\n",
        "    3) The background stays black with white lines (where no data is present).\n",
        "    \"\"\"\n",
        "\n",
        "    # (A) Build black court background\n",
        "    court_img = build_heatmap_court_background_black()\n",
        "    Hc, Wc = court_img.shape[:2]\n",
        "    n_frames = len(homography_matrices)\n",
        "\n",
        "    # (B) Bounces => direct drawing\n",
        "    bounce_overlay = court_img.copy()\n",
        "    for i in range(n_frames):\n",
        "        if i not in bounces:\n",
        "            continue\n",
        "        bx, by = ball_track[i]\n",
        "        inv_mat = homography_matrices[i]\n",
        "        if bx is None or inv_mat is None:\n",
        "            continue\n",
        "\n",
        "        pt = np.array([[[bx, by]]], dtype=np.float32)\n",
        "        mapped = cv2.perspectiveTransform(pt, inv_mat)\n",
        "        xx, yy = int(mapped[0, 0, 0]), int(mapped[0, 0, 1])\n",
        "        if 0 <= xx < Wc and 0 <= yy < Hc:\n",
        "            # Increase radius from 5 to 8 for bigger circles\n",
        "            cv2.circle(bounce_overlay, (xx, yy), 12, (0, 255, 255), -1)  # fill (yellow)\n",
        "            cv2.circle(bounce_overlay, (xx, yy), 12, (0, 0, 255), 2)  # outline (red)\n",
        "\n",
        "    # (C) Players => aggregator -> blur -> custom colormap\n",
        "    player_acc = np.zeros((Hc, Wc), dtype=np.float32)\n",
        "    for i in range(n_frames):\n",
        "        inv_mat = homography_matrices[i]\n",
        "        if inv_mat is None:\n",
        "            continue\n",
        "\n",
        "        # top\n",
        "        for bbox, center_pt in persons_top[i]:\n",
        "            if bbox is not None and len(bbox) == 4:\n",
        "                cx, cy = center_pt\n",
        "                pt = np.array([[[cx, cy]]], dtype=np.float32)\n",
        "                mapped = cv2.perspectiveTransform(pt, inv_mat)\n",
        "                xx, yy = int(mapped[0, 0, 0]), int(mapped[0, 0, 1])\n",
        "                if 0 <= xx < Wc and 0 <= yy < Hc:\n",
        "                    cv2.circle(player_acc, (xx, yy), 10, 1.0, -1)\n",
        "\n",
        "        # bottom\n",
        "        for bbox, center_pt in persons_bottom[i]:\n",
        "            if bbox is not None and len(bbox) == 4:\n",
        "                cx, cy = center_pt\n",
        "                pt = np.array([[[cx, cy]]], dtype=np.float32)\n",
        "                mapped = cv2.perspectiveTransform(pt, inv_mat)\n",
        "                xx, yy = int(mapped[0, 0, 0]), int(mapped[0, 0, 1])\n",
        "                if 0 <= xx < Wc and 0 <= yy < Hc:\n",
        "                    cv2.circle(player_acc, (xx, yy), 10, 1.0, -1)\n",
        "\n",
        "    # blur => smoother distribution\n",
        "    player_blurred = cv2.GaussianBlur(player_acc, (blur_ksize, blur_ksize), 0)\n",
        "\n",
        "    # (D) Convert blurred player data -> custom colormap\n",
        "    mx = player_blurred.max()\n",
        "    if mx < 1e-8:\n",
        "        # no data\n",
        "        player_overlay = court_img.copy()\n",
        "    else:\n",
        "        norm = (player_blurred / mx * 255).astype(np.uint8)\n",
        "        custom_cmap = build_custom_colormap_black_purple_red_green_yellow()\n",
        "        player_heat = cv2.applyColorMap(norm, custom_cmap)\n",
        "        player_overlay = cv2.addWeighted(court_img, 1.0, player_heat, alpha, 0.0)\n",
        "\n",
        "    # (E) Save\n",
        "    cv2.imwrite(output_bounce_heatmap, bounce_overlay)\n",
        "    cv2.imwrite(output_player_heatmap, player_overlay)\n",
        "    print(f\"Saved bounce heatmap to: {output_bounce_heatmap}\")\n",
        "    print(f\"Saved player heatmap to: {output_player_heatmap}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3ydWd6yahqV"
      },
      "outputs": [],
      "source": [
        "## Ball Detection\n",
        "\n",
        "class BallDetector:\n",
        "    def __init__(self, path_model=None, device='cuda'):\n",
        "        self.model = BallTrackerNet(input_channels=9, out_channels=256)\n",
        "        self.device = device\n",
        "        if path_model:\n",
        "            self.model.load_state_dict(torch.load(path_model, map_location=device))\n",
        "            self.model = self.model.to(device)\n",
        "            self.model.eval()\n",
        "        self.width = 640\n",
        "        self.height = 360\n",
        "\n",
        "    def infer_model(self, frames):\n",
        "        \"\"\" Run pretrained model on a consecutive list of frames\n",
        "        :params\n",
        "            frames: list of consecutive video frames\n",
        "        :return\n",
        "            ball_track: list of detected ball points\n",
        "        \"\"\"\n",
        "        ball_track = [(None, None)]*2\n",
        "        prev_pred = [None, None]\n",
        "        for num in tqdm(range(2, len(frames))):\n",
        "            img = cv2.resize(frames[num], (self.width, self.height))\n",
        "            img_prev = cv2.resize(frames[num-1], (self.width, self.height))\n",
        "            img_preprev = cv2.resize(frames[num-2], (self.width, self.height))\n",
        "            imgs = np.concatenate((img, img_prev, img_preprev), axis=2)\n",
        "            imgs = imgs.astype(np.float32)/255.0\n",
        "            imgs = np.rollaxis(imgs, 2, 0)\n",
        "            inp = np.expand_dims(imgs, axis=0)\n",
        "\n",
        "            out = self.model(torch.from_numpy(inp).float().to(self.device))\n",
        "            output = out.argmax(dim=1).detach().cpu().numpy()\n",
        "            x_pred, y_pred = self.postprocess(output, prev_pred)\n",
        "            prev_pred = [x_pred, y_pred]\n",
        "            ball_track.append((x_pred, y_pred))\n",
        "        return ball_track\n",
        "\n",
        "    def postprocess(self, feature_map, prev_pred, scale=2, max_dist=80):\n",
        "        \"\"\"\n",
        "        :params\n",
        "            feature_map: feature map with shape (1,360,640)\n",
        "            prev_pred: [x,y] coordinates of ball prediction from previous frame\n",
        "            scale: scale for conversion to original shape (720,1280)\n",
        "            max_dist: maximum distance from previous ball detection to remove outliers\n",
        "        :return\n",
        "            x,y ball coordinates\n",
        "        \"\"\"\n",
        "        feature_map *= 255\n",
        "        feature_map = feature_map.reshape((self.height, self.width))\n",
        "        feature_map = feature_map.astype(np.uint8)\n",
        "        ret, heatmap = cv2.threshold(feature_map, 127, 255, cv2.THRESH_BINARY)\n",
        "        circles = cv2.HoughCircles(heatmap, cv2.HOUGH_GRADIENT, dp=1, minDist=1, param1=50, param2=2, minRadius=2,\n",
        "                                   maxRadius=7)\n",
        "        x, y = None, None\n",
        "        if circles is not None:\n",
        "            if prev_pred[0]:\n",
        "                for i in range(len(circles[0])):\n",
        "                    x_temp = circles[0][i][0]*scale\n",
        "                    y_temp = circles[0][i][1]*scale\n",
        "                    dist = distance.euclidean((x_temp, y_temp), prev_pred)\n",
        "                    if dist < max_dist:\n",
        "                        x, y = x_temp, y_temp\n",
        "                        break\n",
        "            else:\n",
        "                x = circles[0][0][0]*scale\n",
        "                y = circles[0][0][1]*scale\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDOiRyHxaXWn"
      },
      "outputs": [],
      "source": [
        "## Court Reference\n",
        "\n",
        "\n",
        "class CourtReference:\n",
        "    \"\"\"\n",
        "    Court reference model\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.baseline_top = ((286, 561), (1379, 561))\n",
        "        self.baseline_bottom = ((286, 2935), (1379, 2935))\n",
        "        self.net = ((286, 1748), (1379, 1748))\n",
        "        self.left_court_line = ((286, 561), (286, 2935))\n",
        "        self.right_court_line = ((1379, 561), (1379, 2935))\n",
        "        self.left_inner_line = ((423, 561), (423, 2935))\n",
        "        self.right_inner_line = ((1242, 561), (1242, 2935))\n",
        "        self.middle_line = ((832, 1110), (832, 2386))\n",
        "        self.top_inner_line = ((423, 1110), (1242, 1110))\n",
        "        self.bottom_inner_line = ((423, 2386), (1242, 2386))\n",
        "        self.top_extra_part = (832.5, 580)\n",
        "        self.bottom_extra_part = (832.5, 2910)\n",
        "\n",
        "        self.key_points = [*self.baseline_top, *self.baseline_bottom,\n",
        "                          *self.left_inner_line, *self.right_inner_line,\n",
        "                          *self.top_inner_line, *self.bottom_inner_line,\n",
        "                          *self.middle_line]\n",
        "\n",
        "        self.border_points = [*self.baseline_top, *self.baseline_bottom[::-1]]\n",
        "\n",
        "        self.court_conf = {1: [*self.baseline_top, *self.baseline_bottom],\n",
        "                           2: [self.left_inner_line[0], self.right_inner_line[0], self.left_inner_line[1],\n",
        "                               self.right_inner_line[1]],\n",
        "                           3: [self.left_inner_line[0], self.right_court_line[0], self.left_inner_line[1],\n",
        "                               self.right_court_line[1]],\n",
        "                           4: [self.left_court_line[0], self.right_inner_line[0], self.left_court_line[1],\n",
        "                               self.right_inner_line[1]],\n",
        "                           5: [*self.top_inner_line, *self.bottom_inner_line],\n",
        "                           6: [*self.top_inner_line, self.left_inner_line[1], self.right_inner_line[1]],\n",
        "                           7: [self.left_inner_line[0], self.right_inner_line[0], *self.bottom_inner_line],\n",
        "                           8: [self.right_inner_line[0], self.right_court_line[0], self.right_inner_line[1],\n",
        "                               self.right_court_line[1]],\n",
        "                           9: [self.left_court_line[0], self.left_inner_line[0], self.left_court_line[1],\n",
        "                               self.left_inner_line[1]],\n",
        "                           10: [self.top_inner_line[0], self.middle_line[0], self.bottom_inner_line[0],\n",
        "                                self.middle_line[1]],\n",
        "                           11: [self.middle_line[0], self.top_inner_line[1], self.middle_line[1],\n",
        "                                self.bottom_inner_line[1]],\n",
        "                           12: [*self.bottom_inner_line, self.left_inner_line[1], self.right_inner_line[1]]}\n",
        "        self.line_width = 1\n",
        "        self.court_width = 1117\n",
        "        self.court_height = 2408\n",
        "        self.top_bottom_border = 549\n",
        "        self.right_left_border = 274\n",
        "        self.court_total_width = self.court_width + self.right_left_border * 2\n",
        "        self.court_total_height = self.court_height + self.top_bottom_border * 2\n",
        "        self.court = self.build_court_reference()\n",
        "\n",
        "        # self.court = cv2.cvtColor(cv2.imread('court_configurations/court_reference.png'), cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    def build_court_reference(self):\n",
        "        \"\"\"\n",
        "        Create court reference image using the lines positions\n",
        "        \"\"\"\n",
        "        court = np.zeros((self.court_height + 2 * self.top_bottom_border, self.court_width + 2 * self.right_left_border), dtype=np.uint8)\n",
        "        cv2.line(court, *self.baseline_top, 1, self.line_width)\n",
        "        cv2.line(court, *self.baseline_bottom, 1, self.line_width)\n",
        "        cv2.line(court, *self.net, 1, self.line_width)\n",
        "        cv2.line(court, *self.top_inner_line, 1, self.line_width)\n",
        "        cv2.line(court, *self.bottom_inner_line, 1, self.line_width)\n",
        "        cv2.line(court, *self.left_court_line, 1, self.line_width)\n",
        "        cv2.line(court, *self.right_court_line, 1, self.line_width)\n",
        "        cv2.line(court, *self.left_inner_line, 1, self.line_width)\n",
        "        cv2.line(court, *self.right_inner_line, 1, self.line_width)\n",
        "        cv2.line(court, *self.middle_line, 1, self.line_width)\n",
        "        court = cv2.dilate(court, np.ones((5, 5), dtype=np.uint8))\n",
        "        # court = cv2.dilate(court, np.ones((7, 7), dtype=np.uint8))\n",
        "        # plt.imsave('court_configurations/court_reference.png', court, cmap='gray')\n",
        "        # self.court = court\n",
        "        return court\n",
        "\n",
        "    def get_important_lines(self):\n",
        "        \"\"\"\n",
        "        Returns all lines of the court\n",
        "        \"\"\"\n",
        "        lines = [*self.baseline_top, *self.baseline_bottom, *self.net, *self.left_court_line, *self.right_court_line,\n",
        "                 *self.left_inner_line, *self.right_inner_line, *self.middle_line,\n",
        "                 *self.top_inner_line, *self.bottom_inner_line]\n",
        "        return lines\n",
        "\n",
        "    def get_extra_parts(self):\n",
        "        parts = [self.top_extra_part, self.bottom_extra_part]\n",
        "        return parts\n",
        "\n",
        "    def save_all_court_configurations(self):\n",
        "        \"\"\"\n",
        "        Create all configurations of 4 points on court reference\n",
        "        \"\"\"\n",
        "        for i, conf in self.court_conf.items():\n",
        "            c = cv2.cvtColor(255 - self.court, cv2.COLOR_GRAY2BGR)\n",
        "            for p in conf:\n",
        "                c = cv2.circle(c, p, 15, (0, 0, 255), 30)\n",
        "            cv2.imwrite(f'court_configurations/court_conf_{i}.png', c)\n",
        "\n",
        "    def get_court_mask(self, mask_type=0):\n",
        "        \"\"\"\n",
        "        Get mask of the court\n",
        "        \"\"\"\n",
        "        mask = np.ones_like(self.court)\n",
        "        if mask_type == 1:  # Bottom half court\n",
        "            # mask[:self.net[0][1] - 1000, :] = 0\n",
        "            mask[:self.net[0][1], :] = 0\n",
        "        elif mask_type == 2:  # Top half court\n",
        "            mask[self.net[0][1]:, :] = 0\n",
        "        elif mask_type == 3: # court without margins\n",
        "            mask[:self.baseline_top[0][1], :] = 0\n",
        "            mask[self.baseline_bottom[0][1]:, :] = 0\n",
        "            mask[:, :self.left_court_line[0][0]] = 0\n",
        "            mask[:, self.right_court_line[0][0]:] = 0\n",
        "        return mask\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    c = CourtReference()\n",
        "    c.build_court_reference()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pV0yckZ2PZSu"
      },
      "outputs": [],
      "source": [
        "## Homography\n",
        "\n",
        "court_ref = CourtReference()\n",
        "refer_kps = np.array(court_ref.key_points, dtype=np.float32).reshape((-1, 1, 2))\n",
        "\n",
        "court_conf_ind = {}\n",
        "for i in range(len(court_ref.court_conf)):\n",
        "    conf = court_ref.court_conf[i+1]\n",
        "    inds = []\n",
        "    for j in range(4):\n",
        "        inds.append(court_ref.key_points.index(conf[j]))\n",
        "    court_conf_ind[i+1] = inds\n",
        "\n",
        "def get_trans_matrix(points):\n",
        "    \"\"\"\n",
        "    Determine the best homography matrix from court points\n",
        "    \"\"\"\n",
        "    matrix_trans = None\n",
        "    dist_max = np.Inf\n",
        "    for conf_ind in range(1, 13):\n",
        "        conf = court_ref.court_conf[conf_ind]\n",
        "\n",
        "        inds = court_conf_ind[conf_ind]\n",
        "        inters = [points[inds[0]], points[inds[1]], points[inds[2]], points[inds[3]]]\n",
        "        if None not in inters:\n",
        "            matrix, _ = cv2.findHomography(np.float32(conf), np.float32(inters), method=0)\n",
        "            trans_kps = cv2.perspectiveTransform(refer_kps, matrix).squeeze(1)\n",
        "            dists = []\n",
        "            for i in range(12):\n",
        "                if i not in inds and points[i] is not None:\n",
        "                    dists.append(distance.euclidean(points[i], trans_kps[i]))\n",
        "            dist_median = np.mean(dists)\n",
        "            if dist_median < dist_max:\n",
        "                matrix_trans = matrix\n",
        "                dist_max = dist_median\n",
        "    return matrix_trans\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YJJTXlQPq1e"
      },
      "outputs": [],
      "source": [
        "## Court Detection\n",
        "\n",
        "class CourtDetectorNet():\n",
        "    def __init__(self, path_model=None,  device='cuda'):\n",
        "        self.model = BallTrackerNet(out_channels=15)\n",
        "        self.device = device\n",
        "        if path_model:\n",
        "            self.model.load_state_dict(torch.load(path_model, map_location=device))\n",
        "            self.model = self.model.to(device)\n",
        "            self.model.eval()\n",
        "\n",
        "    def infer_model(self, frames):\n",
        "        output_width = 640\n",
        "        output_height = 360\n",
        "        scale = 2\n",
        "\n",
        "        kps_res = []\n",
        "        matrixes_res = []\n",
        "        for num_frame, image in enumerate(tqdm(frames)):\n",
        "            img = cv2.resize(image, (output_width, output_height))\n",
        "            inp = (img.astype(np.float32) / 255.)\n",
        "            inp = torch.tensor(np.rollaxis(inp, 2, 0))\n",
        "            inp = inp.unsqueeze(0)\n",
        "\n",
        "            out = self.model(inp.float().to(self.device))[0]\n",
        "            pred = F.sigmoid(out).detach().cpu().numpy()\n",
        "\n",
        "            points = []\n",
        "            for kps_num in range(14):\n",
        "                heatmap = (pred[kps_num]*255).astype(np.uint8)\n",
        "                ret, heatmap = cv2.threshold(heatmap, 170, 255, cv2.THRESH_BINARY)\n",
        "                circles = cv2.HoughCircles(heatmap, cv2.HOUGH_GRADIENT, dp=1, minDist=20, param1=50, param2=2,\n",
        "                                           minRadius=10, maxRadius=25)\n",
        "                if circles is not None:\n",
        "                    x_pred = circles[0][0][0]*scale\n",
        "                    y_pred = circles[0][0][1]*scale\n",
        "                    if kps_num not in [8, 12, 9]:\n",
        "                        x_pred, y_pred = refine_kps(image, int(y_pred), int(x_pred), crop_size=40)\n",
        "                    points.append((x_pred, y_pred))\n",
        "                else:\n",
        "                    points.append(None)\n",
        "\n",
        "            matrix_trans = get_trans_matrix(points)\n",
        "            points = None\n",
        "            if matrix_trans is not None:\n",
        "                points = cv2.perspectiveTransform(refer_kps, matrix_trans)\n",
        "                matrix_trans = cv2.invert(matrix_trans)[1]\n",
        "            kps_res.append(points)\n",
        "            matrixes_res.append(matrix_trans)\n",
        "\n",
        "        return matrixes_res, kps_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voc4sJDxPiuB"
      },
      "outputs": [],
      "source": [
        "## Postprocess\n",
        "\n",
        "def line_intersection(line1, line2):\n",
        "    \"\"\"\n",
        "    Find 2 lines intersection point\n",
        "    \"\"\"\n",
        "    l1 = Line((line1[0], line1[1]), (line1[2], line1[3]))\n",
        "    l2 = Line((line2[0], line2[1]), (line2[2], line2[3]))\n",
        "\n",
        "    intersection = l1.intersection(l2)\n",
        "    point = None\n",
        "    if len(intersection) > 0:\n",
        "        if isinstance(intersection[0], Point2D):\n",
        "            point = intersection[0].coordinates\n",
        "    return point\n",
        "\n",
        "def refine_kps(img, x_ct, y_ct, crop_size=40):\n",
        "    refined_x_ct, refined_y_ct = x_ct, y_ct\n",
        "\n",
        "    img_height, img_width = img.shape[:2]\n",
        "    x_min = max(x_ct-crop_size, 0)\n",
        "    x_max = min(img_height, x_ct+crop_size)\n",
        "    y_min = max(y_ct-crop_size, 0)\n",
        "    y_max = min(img_width, y_ct+crop_size)\n",
        "\n",
        "    img_crop = img[x_min:x_max, y_min:y_max]\n",
        "    lines = detect_lines(img_crop)\n",
        "    # print('lines = ', lines)\n",
        "\n",
        "    if len(lines) > 1:\n",
        "        lines = merge_lines(lines)\n",
        "        if len(lines) == 2:\n",
        "            inters = line_intersection(lines[0], lines[1])\n",
        "            if inters:\n",
        "                new_x_ct = int(inters[1])\n",
        "                new_y_ct = int(inters[0])\n",
        "                if new_x_ct > 0 and new_x_ct < img_crop.shape[0] and new_y_ct > 0 and new_y_ct < img_crop.shape[1]:\n",
        "                    refined_x_ct = x_min + new_x_ct\n",
        "                    refined_y_ct = y_min + new_y_ct\n",
        "    return refined_y_ct, refined_x_ct\n",
        "\n",
        "def detect_lines(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.threshold(gray, 155, 255, cv2.THRESH_BINARY)[1]\n",
        "    lines = cv2.HoughLinesP(gray, 1, np.pi / 180, 30, minLineLength=10, maxLineGap=30)\n",
        "    lines = np.squeeze(lines)\n",
        "    if len(lines.shape) > 0:\n",
        "        if len(lines) == 4 and not isinstance(lines[0], np.ndarray):\n",
        "            lines = [lines]\n",
        "    else:\n",
        "        lines = []\n",
        "    return lines\n",
        "\n",
        "def merge_lines(lines):\n",
        "    lines = sorted(lines, key=lambda item: item[0])\n",
        "    mask = [True] * len(lines)\n",
        "    new_lines = []\n",
        "\n",
        "    for i, line in enumerate(lines):\n",
        "        if mask[i]:\n",
        "            for j, s_line in enumerate(lines[i + 1:]):\n",
        "                if mask[i + j + 1]:\n",
        "                    x1, y1, x2, y2 = line\n",
        "                    x3, y3, x4, y4 = s_line\n",
        "                    dist1 = distance.euclidean((x1, y1), (x3, y3))\n",
        "                    dist2 = distance.euclidean((x2, y2), (x4, y4))\n",
        "                    if dist1 < 20 and dist2 < 20:\n",
        "                        line = np.array([int((x1+x3)/2), int((y1+y3)/2), int((x2+x4)/2), int((y2+y4)/2)])\n",
        "                        mask[i + j + 1] = False\n",
        "            new_lines.append(line)\n",
        "    return new_lines\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhT-_lC1PzeE"
      },
      "outputs": [],
      "source": [
        "## Person Detection\n",
        "\n",
        "class PersonDetector():\n",
        "    def __init__(self, dtype=torch.FloatTensor):\n",
        "        self.detection_model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "        self.detection_model = self.detection_model.to(dtype)\n",
        "        self.detection_model.eval()\n",
        "        self.dtype = dtype\n",
        "        self.court_ref = CourtReference()\n",
        "        self.ref_top_court = self.court_ref.get_court_mask(2)\n",
        "        self.ref_bottom_court = self.court_ref.get_court_mask(1)\n",
        "        self.point_person_top = None\n",
        "        self.point_person_bottom = None\n",
        "        self.counter_top = 0\n",
        "        self.counter_bottom = 0\n",
        "\n",
        "\n",
        "    def detect(self, image, person_min_score=0.85):\n",
        "        PERSON_LABEL = 1\n",
        "        frame_tensor = image.transpose((2, 0, 1)) / 255\n",
        "        frame_tensor = torch.from_numpy(frame_tensor).unsqueeze(0).float().to(self.dtype)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds = self.detection_model(frame_tensor)\n",
        "\n",
        "        persons_boxes = []\n",
        "        probs = []\n",
        "        for box, label, score in zip(preds[0]['boxes'][:], preds[0]['labels'], preds[0]['scores']):\n",
        "            if label == PERSON_LABEL and score > person_min_score:\n",
        "                persons_boxes.append(box.detach().cpu().numpy())\n",
        "                probs.append(score.detach().cpu().numpy())\n",
        "        return persons_boxes, probs\n",
        "\n",
        "    def detect_top_and_bottom_players(self, image, inv_matrix, filter_players=False):\n",
        "        matrix = cv2.invert(inv_matrix)[1]\n",
        "        mask_top_court = cv2.warpPerspective(self.ref_top_court, matrix, image.shape[1::-1])\n",
        "        mask_bottom_court = cv2.warpPerspective(self.ref_bottom_court, matrix, image.shape[1::-1])\n",
        "        person_bboxes_top, person_bboxes_bottom = [], []\n",
        "\n",
        "        bboxes, probs = self.detect(image, person_min_score=0.85)\n",
        "        if len(bboxes) > 0:\n",
        "            person_points = [[int((bbox[2] + bbox[0]) / 2), int(bbox[3])] for bbox in bboxes]\n",
        "            person_bboxes = list(zip(bboxes, person_points))\n",
        "\n",
        "            person_bboxes_top = [pt for pt in person_bboxes if mask_top_court[pt[1][1]-1, pt[1][0]] == 1]\n",
        "            person_bboxes_bottom = [pt for pt in person_bboxes if mask_bottom_court[pt[1][1] - 1, pt[1][0]] == 1]\n",
        "\n",
        "            if filter_players:\n",
        "                person_bboxes_top, person_bboxes_bottom = self.filter_players(person_bboxes_top, person_bboxes_bottom,\n",
        "                                                                              matrix)\n",
        "        return person_bboxes_top, person_bboxes_bottom\n",
        "\n",
        "    def filter_players(self, person_bboxes_top, person_bboxes_bottom, matrix):\n",
        "        \"\"\"\n",
        "        Leave one person at the top and bottom of the tennis court\n",
        "        \"\"\"\n",
        "        refer_kps = np.array(self.court_ref.key_points[12:], dtype=np.float32).reshape((-1, 1, 2))\n",
        "        trans_kps = cv2.perspectiveTransform(refer_kps, matrix)\n",
        "        center_top_court = trans_kps[0][0]\n",
        "        center_bottom_court = trans_kps[1][0]\n",
        "        if len(person_bboxes_top) > 1:\n",
        "            dists = [distance.euclidean(x[1], center_top_court) for x in person_bboxes_top]\n",
        "            ind = dists.index(min(dists))\n",
        "            person_bboxes_top = [person_bboxes_top[ind]]\n",
        "        if len(person_bboxes_bottom) > 1:\n",
        "            dists = [distance.euclidean(x[1], center_bottom_court) for x in person_bboxes_bottom]\n",
        "            ind = dists.index(min(dists))\n",
        "            person_bboxes_bottom = [person_bboxes_bottom[ind]]\n",
        "        return person_bboxes_top, person_bboxes_bottom\n",
        "\n",
        "    def track_players(self, frames, matrix_all, filter_players=False):\n",
        "        persons_top = []\n",
        "        persons_bottom = []\n",
        "        min_len = min(len(frames), len(matrix_all))\n",
        "        for num_frame in tqdm(range(min_len)):\n",
        "            img = frames[num_frame]\n",
        "            if matrix_all[num_frame] is not None:\n",
        "                inv_matrix = matrix_all[num_frame]\n",
        "                person_top, person_bottom = self.detect_top_and_bottom_players(img, inv_matrix, filter_players)\n",
        "            else:\n",
        "                person_top, person_bottom = [], []\n",
        "            persons_top.append(person_top)\n",
        "            persons_bottom.append(person_bottom)\n",
        "        return persons_top, persons_bottom\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkfEI5d5Q8D-"
      },
      "outputs": [],
      "source": [
        "## Bounce Detection\n",
        "\n",
        "class BounceDetector:\n",
        "    def __init__(self, path_model=None):\n",
        "        self.model = ctb.CatBoostRegressor()\n",
        "        self.threshold = 0.45\n",
        "        if path_model:\n",
        "            self.load_model(path_model)\n",
        "\n",
        "    def load_model(self, path_model):\n",
        "        self.model.load_model(path_model)\n",
        "\n",
        "    def prepare_features(self, x_ball, y_ball):\n",
        "        labels = pd.DataFrame({'frame': range(len(x_ball)), 'x-coordinate': x_ball, 'y-coordinate': y_ball})\n",
        "\n",
        "        num = 3\n",
        "        eps = 1e-15\n",
        "        for i in range(1, num):\n",
        "            labels['x_lag_{}'.format(i)] = labels['x-coordinate'].shift(i)\n",
        "            labels['x_lag_inv_{}'.format(i)] = labels['x-coordinate'].shift(-i)\n",
        "            labels['y_lag_{}'.format(i)] = labels['y-coordinate'].shift(i)\n",
        "            labels['y_lag_inv_{}'.format(i)] = labels['y-coordinate'].shift(-i)\n",
        "            labels['x_diff_{}'.format(i)] = abs(labels['x_lag_{}'.format(i)] - labels['x-coordinate'])\n",
        "            labels['y_diff_{}'.format(i)] = labels['y_lag_{}'.format(i)] - labels['y-coordinate']\n",
        "            labels['x_diff_inv_{}'.format(i)] = abs(labels['x_lag_inv_{}'.format(i)] - labels['x-coordinate'])\n",
        "            labels['y_diff_inv_{}'.format(i)] = labels['y_lag_inv_{}'.format(i)] - labels['y-coordinate']\n",
        "            labels['x_div_{}'.format(i)] = abs(labels['x_diff_{}'.format(i)]/(labels['x_diff_inv_{}'.format(i)] + eps))\n",
        "            labels['y_div_{}'.format(i)] = labels['y_diff_{}'.format(i)]/(labels['y_diff_inv_{}'.format(i)] + eps)\n",
        "\n",
        "        for i in range(1, num):\n",
        "            labels = labels[labels['x_lag_{}'.format(i)].notna()]\n",
        "            labels = labels[labels['x_lag_inv_{}'.format(i)].notna()]\n",
        "        labels = labels[labels['x-coordinate'].notna()]\n",
        "\n",
        "        colnames_x = ['x_diff_{}'.format(i) for i in range(1, num)] + \\\n",
        "                     ['x_diff_inv_{}'.format(i) for i in range(1, num)] + \\\n",
        "                     ['x_div_{}'.format(i) for i in range(1, num)]\n",
        "        colnames_y = ['y_diff_{}'.format(i) for i in range(1, num)] + \\\n",
        "                     ['y_diff_inv_{}'.format(i) for i in range(1, num)] + \\\n",
        "                     ['y_div_{}'.format(i) for i in range(1, num)]\n",
        "        colnames = colnames_x + colnames_y\n",
        "\n",
        "        features = labels[colnames]\n",
        "        return features, list(labels['frame'])\n",
        "\n",
        "    def predict(self, x_ball, y_ball, smooth=True):\n",
        "        if smooth:\n",
        "            x_ball, y_ball = self.smooth_predictions(x_ball, y_ball)\n",
        "        features, num_frames = self.prepare_features(x_ball, y_ball)\n",
        "        preds = self.model.predict(features)\n",
        "        ind_bounce = np.where(preds > self.threshold)[0]\n",
        "        if len(ind_bounce) > 0:\n",
        "            ind_bounce = self.postprocess(ind_bounce, preds)\n",
        "        frames_bounce = [num_frames[x] for x in ind_bounce]\n",
        "        return set(frames_bounce)\n",
        "\n",
        "    def smooth_predictions(self, x_ball, y_ball):\n",
        "        is_none = [int(x is None) for x in x_ball]\n",
        "        interp = 5\n",
        "        counter = 0\n",
        "        for num in range(interp, len(x_ball)-1):\n",
        "            if not x_ball[num] and sum(is_none[num-interp:num]) == 0 and counter < 3:\n",
        "                x_ext, y_ext = self.extrapolate(x_ball[num-interp:num], y_ball[num-interp:num])\n",
        "                x_ball[num] = x_ext\n",
        "                y_ball[num] = y_ext\n",
        "                is_none[num] = 0\n",
        "                if x_ball[num+1]:\n",
        "                    dist = distance.euclidean((x_ext, y_ext), (x_ball[num+1], y_ball[num+1]))\n",
        "                    if dist > 80:\n",
        "                        x_ball[num+1], y_ball[num+1], is_none[num+1] = None, None, 1\n",
        "                counter += 1\n",
        "            else:\n",
        "                counter = 0\n",
        "        return x_ball, y_ball\n",
        "\n",
        "    def extrapolate(self, x_coords, y_coords):\n",
        "        xs = list(range(len(x_coords)))\n",
        "        func_x = CubicSpline(xs, x_coords, bc_type='natural')\n",
        "        x_ext = func_x(len(x_coords))\n",
        "        func_y = CubicSpline(xs, y_coords, bc_type='natural')\n",
        "        y_ext = func_y(len(x_coords))\n",
        "        return float(x_ext), float(y_ext)\n",
        "\n",
        "    def postprocess(self, ind_bounce, preds):\n",
        "        ind_bounce_filtered = [ind_bounce[0]]\n",
        "        for i in range(1, len(ind_bounce)):\n",
        "            if (ind_bounce[i] - ind_bounce[i-1]) != 1:\n",
        "                cur_ind = ind_bounce[i]\n",
        "                ind_bounce_filtered.append(cur_ind)\n",
        "            elif preds[ind_bounce[i]] > preds[ind_bounce[i-1]]:\n",
        "                ind_bounce_filtered[-1] = ind_bounce[i]\n",
        "        return ind_bounce_filtered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjQmlTVusG4K",
        "outputId": "582077d5-e5f8-4bb0-c7d3-0f0e6e9f8007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original input: 1280x720, fps=30.00\n",
            "Video is already 1280x720; using input directly.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pyscenedetect:VideoManager is deprecated and will be removed.\n",
            "INFO:pyscenedetect:Loaded 1 video, framerate: 30.000 FPS, resolution: 1280 x 720\n",
            "INFO:pyscenedetect:Detecting scenes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1001 frames at 30 fps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pyscenedetect:`base_timecode` argument is deprecated and has no effect.\n",
            "WARNING:py.warnings:<ipython-input-24-19aeba935135>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.model.load_state_dict(torch.load(path_model, map_location=device))\n",
            "\n",
            "100%|██████████| 999/999 [00:22<00:00, 44.20it/s]\n",
            "100%|██████████| 1001/1001 [01:22<00:00, 12.13it/s]\n",
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "\n",
            "100%|██████████| 1001/1001 [00:37<00:00, 26.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Composing final frames...\n",
            "[write] Finished writing /content/drive/MyDrive/ASA Tennis Bounds Project/models/court_detection_model/detectron2/post_processing/game2/game2_output.mp4\n",
            "[write] Finished writing /content/drive/MyDrive/ASA Tennis Bounds Project/models/court_detection_model/detectron2/post_processing/game2/game2_minimap.mp4\n",
            "Saved bounce heatmap to: /content/drive/MyDrive/ASA Tennis Bounds Project/models/court_detection_model/detectron2/post_processing/game2/heatmap/game2_bounce_heatmap.png\n",
            "Saved player heatmap to: /content/drive/MyDrive/ASA Tennis Bounds Project/models/court_detection_model/detectron2/post_processing/game2/heatmap/game2_player_heatmap.png\n",
            "Done, saved to /content/drive/MyDrive/ASA Tennis Bounds Project/models/court_detection_model/detectron2/post_processing/game2/game2_output.mp4. Overall time: 182.48s\n"
          ]
        }
      ],
      "source": [
        "keypoint_names = [\n",
        "    \"BTL\",\n",
        "    \"BTR\",\n",
        "    \"BBL\",\n",
        "    \"BBR\",\n",
        "    \"BTLI\",\n",
        "    \"BBLI\",\n",
        "    \"BTRI\",\n",
        "    \"BBRI\",\n",
        "    \"ITL\",\n",
        "    \"ITR\",\n",
        "    \"IBL\",\n",
        "    \"IBR\",\n",
        "    \"ITM\",\n",
        "    \"IBM\",\n",
        "]\n",
        "\n",
        "court_lines = [\n",
        "    (\"BTL\", \"BTLI\"),\n",
        "    (\"BTLI\", \"BTRI\"),\n",
        "    (\"BTRI\", \"BTR\"),\n",
        "    (\"BTL\", \"BBL\"),\n",
        "    (\"BTR\", \"BBR\"),\n",
        "    (\"BBL\", \"BBLI\"),\n",
        "    (\"BBLI\", \"BBRI\"),\n",
        "    (\"BBLI\", \"IBL\"),\n",
        "    (\"BBRI\", \"IBR\"),\n",
        "    (\"BBRI\", \"BBR\"),\n",
        "    (\"BTLI\", \"ITL\"),\n",
        "    (\"BTRI\", \"ITR\"),\n",
        "    (\"ITL\", \"ITM\"),\n",
        "    (\"ITM\", \"IBM\"),\n",
        "    (\"ITL\", \"IBL\"),\n",
        "    (\"ITR\", \"IBR\"),\n",
        "    (\"IBL\", \"IBM\"),\n",
        "    (\"IBM\", \"IBR\"),\n",
        "    (\"ITM\", \"ITR\"),\n",
        "]\n",
        "\n",
        "\n",
        "def ensure_720p(input_path, intermediate_path):\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    cap.release()\n",
        "\n",
        "    print(f\"Original input: {width}x{height}, fps={fps:.2f}\")\n",
        "    if (width != 1280) or (height != 720):\n",
        "        print(f\"Resizing from ({width}x{height}) to (1280x720) -> {intermediate_path}\")\n",
        "        cap_in = cv2.VideoCapture(input_path)\n",
        "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "        out = cv2.VideoWriter(intermediate_path, fourcc, fps, (1280, 720))\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap_in.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = cv2.resize(frame, (1280, 720), interpolation=cv2.INTER_AREA)\n",
        "            out.write(frame)\n",
        "\n",
        "        cap_in.release()\n",
        "        out.release()\n",
        "        print(f\"Finished writing intermediate: {intermediate_path}\")\n",
        "        return intermediate_path\n",
        "    else:\n",
        "        print(\"Video is already 1280x720; using input directly.\")\n",
        "        return input_path\n",
        "\n",
        "\n",
        "def read_video(path_video):\n",
        "    cap = cv2.VideoCapture(path_video)\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    frames = []\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frames.append(frame)\n",
        "    cap.release()\n",
        "    return frames, fps\n",
        "\n",
        "\n",
        "def get_court_img():\n",
        "    \"\"\"Build a 720p-like minimap with white lines on black background.\"\"\"\n",
        "    court_ref = CourtReference()\n",
        "    court = court_ref.build_court_reference()\n",
        "    court = cv2.dilate(court, np.ones((10, 10), dtype=np.uint8))\n",
        "    court_img = (np.stack((court, court, court), axis=2) * 255).astype(np.uint8)\n",
        "    return court_img\n",
        "\n",
        "\n",
        "def draw_court_keypoints_and_lines(frame, kps, frame_width, frame_height):\n",
        "    \"\"\"\n",
        "    Draw tennis court lines (green) and keypoints (red) on 'frame'.\n",
        "    \"\"\"\n",
        "    for start_name, end_name in court_lines:\n",
        "        try:\n",
        "            s_idx = keypoint_names.index(start_name)\n",
        "            e_idx = keypoint_names.index(end_name)\n",
        "            if kps[s_idx] is None or kps[e_idx] is None:\n",
        "                continue\n",
        "            x1 = int(kps[s_idx][0, 0] * frame_width / 1280)\n",
        "            y1 = int(kps[s_idx][0, 1] * frame_height / 720)\n",
        "            x2 = int(kps[e_idx][0, 0] * frame_width / 1280)\n",
        "            y2 = int(kps[e_idx][0, 1] * frame_height / 720)\n",
        "            cv2.line(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        except ValueError:\n",
        "            pass\n",
        "\n",
        "    # Keypoints\n",
        "    for i, pt in enumerate(kps):\n",
        "        if pt is None:\n",
        "            continue\n",
        "        x = int(pt[0, 0] * frame_width / 1280)\n",
        "        y = int(pt[0, 1] * frame_height / 720)\n",
        "        cv2.circle(frame, (x, y), 5, (0, 0, 255), -1)\n",
        "        label = keypoint_names[i]\n",
        "        (tw, th), base = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.4, 1)\n",
        "        cv2.rectangle(\n",
        "            frame, (x - 5, y - th - 5), (x - 5 + tw, y - 5), (255, 255, 255), -1\n",
        "        )\n",
        "        cv2.putText(\n",
        "            frame, label, (x - 5, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1\n",
        "        )\n",
        "\n",
        "\n",
        "def main(\n",
        "    frames,\n",
        "    scenes,\n",
        "    bounces,\n",
        "    ball_track,\n",
        "    homography_matrices,\n",
        "    kps_court,\n",
        "    persons_top,\n",
        "    persons_bottom,\n",
        "    draw_trace=True,\n",
        "    trace=7,\n",
        "):\n",
        "    imgs_res = []\n",
        "    minimap_frames = []  # New list to store minimap frames\n",
        "    width_minimap = 166\n",
        "    height_minimap = 350\n",
        "\n",
        "    light_blue = (255, 255, 0)\n",
        "    bounce_color = (0, 255, 255)\n",
        "    box_color = (255, 0, 0)\n",
        "\n",
        "    for start_idx, end_idx in scenes:\n",
        "        valid_count = sum(\n",
        "            1\n",
        "            for idx in range(start_idx, end_idx)\n",
        "            if homography_matrices[idx] is not None\n",
        "        )\n",
        "        scene_len = end_idx - start_idx\n",
        "        scene_rate = valid_count / (scene_len + 1e-15)\n",
        "\n",
        "        if scene_rate > 0.5:\n",
        "            for i in range(start_idx, end_idx):\n",
        "                court_img = get_court_img()\n",
        "                img_res = frames[i]\n",
        "                inv_mat = homography_matrices[i]\n",
        "\n",
        "                # ball\n",
        "                if ball_track[i][0]:\n",
        "                    bx = int(ball_track[i][0])\n",
        "                    by = int(ball_track[i][1])\n",
        "                    if draw_trace:\n",
        "                        for j in range(trace):\n",
        "                            idx = i - j\n",
        "                            if idx < 0:\n",
        "                                break\n",
        "                            if ball_track[idx][0]:\n",
        "                                px, py = ball_track[idx]\n",
        "                                alpha = 1.0 - (j / trace)\n",
        "                                color_fade = tuple(int(c * alpha) for c in light_blue)\n",
        "                                cv2.circle(\n",
        "                                    img_res, (int(px), int(py)), 3, color_fade, -1\n",
        "                                )\n",
        "                    else:\n",
        "                        cv2.circle(img_res, (bx, by), 5, light_blue, -1)\n",
        "                        cv2.putText(\n",
        "                            img_res,\n",
        "                            \"ball\",\n",
        "                            (bx + 8, by + 8),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                            0.8,\n",
        "                            light_blue,\n",
        "                            2,\n",
        "                        )\n",
        "\n",
        "                # ball trace on minimap\n",
        "                if inv_mat is not None and ball_track[i][0]:\n",
        "                    for j in range(trace):\n",
        "                        idx = i - j\n",
        "                        if idx < 0:\n",
        "                            break\n",
        "                        if ball_track[idx][0]:\n",
        "                            px, py = ball_track[idx]\n",
        "                            arr = cv2.perspectiveTransform(\n",
        "                                np.array([[[px, py]]], dtype=np.float32), inv_mat\n",
        "                            )\n",
        "                            alpha_ = 1.0 - (j / trace)\n",
        "                            color_fade = tuple(int(c * alpha_) for c in light_blue)\n",
        "                            mx = int(arr[0, 0, 0])\n",
        "                            my = int(arr[0, 0, 1])\n",
        "                            cv2.circle(court_img, (mx, my), 3, color_fade, 20)\n",
        "\n",
        "                # court lines\n",
        "                if kps_court[i] is not None:\n",
        "                    h, w = img_res.shape[:2]\n",
        "                    draw_court_keypoints_and_lines(img_res, kps_court[i], w, h)\n",
        "\n",
        "                # bounces => up to current frame\n",
        "                if inv_mat is not None:\n",
        "                    for bf in bounces:\n",
        "                        if bf <= i and ball_track[bf][0]:\n",
        "                            bpx, bpy = ball_track[bf]\n",
        "                            arr = cv2.perspectiveTransform(\n",
        "                                np.array([[[bpx, bpy]]], dtype=np.float32), inv_mat\n",
        "                            )\n",
        "                            mx = int(arr[0, 0, 0])\n",
        "                            my = int(arr[0, 0, 1])\n",
        "                            cv2.circle(court_img, (mx, my), 10, bounce_color, 40)\n",
        "\n",
        "                # players\n",
        "                minimap = court_img.copy()\n",
        "\n",
        "                # -- top players => Player 1\n",
        "                for bbox, center_pt in persons_top[i]:\n",
        "                    if bbox is not None and len(bbox) == 4:\n",
        "                        x1, y1, x2, y2 = map(int, bbox)\n",
        "                        # Draw the bounding box on the main frame\n",
        "                        cv2.rectangle(img_res, (x1, y1), (x2, y2), box_color, 2)\n",
        "                        cv2.putText(\n",
        "                            img_res,\n",
        "                            \"Player 1\",\n",
        "                            (x1, y1 - 5),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                            0.7,\n",
        "                            box_color,\n",
        "                            2,\n",
        "                        )\n",
        "                        # For the minimap, use the bottom-center point from PersonDetector\n",
        "                        if inv_mat is not None:\n",
        "                            cx, cy = center_pt  # <--- bottom-center from PersonDetector\n",
        "                            arr = cv2.perspectiveTransform(\n",
        "                                np.array([[[cx, cy]]], dtype=np.float32), inv_mat\n",
        "                            )\n",
        "                            mx = int(arr[0, 0, 0])\n",
        "                            my = int(arr[0, 0, 1])\n",
        "                            if (\n",
        "                                0 <= mx < minimap.shape[1]\n",
        "                                and 0 <= my < minimap.shape[0]\n",
        "                            ):\n",
        "                                cv2.circle(minimap, (mx, my), 48, box_color, -1)\n",
        "\n",
        "                # -- bottom players => Player 2\n",
        "                for bbox, center_pt in persons_bottom[i]:\n",
        "                    if bbox is not None and len(bbox) == 4:\n",
        "                        x1, y1, x2, y2 = map(int, bbox)\n",
        "                        # Draw the bounding box on the main frame\n",
        "                        cv2.rectangle(img_res, (x1, y1), (x2, y2), box_color, 2)\n",
        "                        cv2.putText(\n",
        "                            img_res,\n",
        "                            \"Player 2\",\n",
        "                            (x1, y1 - 5),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                            0.7,\n",
        "                            box_color,\n",
        "                            2,\n",
        "                        )\n",
        "                        # For the minimap, use the bottom-center point from PersonDetector\n",
        "                        if inv_mat is not None:\n",
        "                            cx, cy = center_pt\n",
        "                            arr = cv2.perspectiveTransform(\n",
        "                                np.array([[[cx, cy]]], dtype=np.float32), inv_mat\n",
        "                            )\n",
        "                            mx = int(arr[0, 0, 0])\n",
        "                            my = int(arr[0, 0, 1])\n",
        "                            if (\n",
        "                                0 <= mx < minimap.shape[1]\n",
        "                                and 0 <= my < minimap.shape[0]\n",
        "                            ):\n",
        "                                cv2.circle(minimap, (mx, my), 48, box_color, -1)\n",
        "\n",
        "                # Store the minimap frame\n",
        "                minimap_frames.append(\n",
        "                    cv2.resize(minimap, (width_minimap, height_minimap))\n",
        "                )\n",
        "\n",
        "                # place minimap in main frame as before\n",
        "                H, W = img_res.shape[:2]\n",
        "                minimap_resized = cv2.resize(minimap, (width_minimap, height_minimap))\n",
        "                img_res[0:height_minimap, 0:width_minimap] = minimap_resized\n",
        "\n",
        "                imgs_res.append(img_res)\n",
        "        else:\n",
        "            # If the scene homography is mostly invalid, add blank minimaps\n",
        "            blank_minimap = np.zeros((height_minimap, width_minimap, 3), dtype=np.uint8)\n",
        "            minimap_frames.extend([blank_minimap] * (end_idx - start_idx))\n",
        "            imgs_res += frames[start_idx:end_idx]\n",
        "\n",
        "    return imgs_res, minimap_frames\n",
        "\n",
        "\n",
        "def write(imgs_res, fps, output_path):\n",
        "    if not imgs_res:\n",
        "        print(\"No frames, skipping write.\")\n",
        "        return\n",
        "    H, W = imgs_res[0].shape[:2]\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (W, H))\n",
        "    for frame in imgs_res:\n",
        "        out.write(frame)\n",
        "    out.release()\n",
        "    print(f\"[write] Finished writing {output_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    path_ball_track_model = \"/content/drive/MyDrive/ASA Tennis Bounds Project/models/court_detection_model/detectron2/models/ball_detection_weights/tracknet_weights.pt\"\n",
        "    path_court_model = \"/content/drive/MyDrive/ASA Tennis Bounds Project/models/court_detection_model/detectron2/models/court_detection_weights/model_tennis_court_det.pt\"\n",
        "    path_bounce_model = \"/content/drive/MyDrive/ASA Tennis Bounds Project/models/court_detection_model/detectron2/models/bounce_detection_weights/bounce_detection_weights.cbm\"\n",
        "    path_input_video = \"/content/drive/MyDrive/ASA Tennis Bounds Project/models/court_detection_model/dataset/game2/game2_1280x720.mp4\"\n",
        "    path_intermediate_video = \"/content/drive/MyDrive/ASA Tennis Bounds Project/models/court_detection_model/detectron2/post_processing/game2/game2_edited.mp4\"\n",
        "    path_output_video = \"/content/drive/MyDrive/ASA Tennis Bounds Project/models/court_detection_model/detectron2/post_processing/game2/game2_output.mp4\"\n",
        "\n",
        "    path_output_bounce_heatmap = \"/content/drive/MyDrive/ASA Tennis Bounds Project/models/court_detection_model/detectron2/post_processing/game2/heatmap/game2_bounce_heatmap.png\"\n",
        "    path_output_player_heatmap = \"/content/drive/MyDrive/ASA Tennis Bounds Project/models/court_detection_model/detectron2/post_processing/game2/heatmap/game2_player_heatmap.png\"\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    start_time = time.time()\n",
        "\n",
        "    # 1) Scale to 720p if needed\n",
        "    final_input = ensure_720p(path_input_video, path_intermediate_video)\n",
        "\n",
        "    # 2) Read frames\n",
        "    frames, fps = read_video(final_input)\n",
        "    print(f\"Loaded {len(frames)} frames at {fps} fps\")\n",
        "\n",
        "    # 3) Scene detection\n",
        "    video_manager = VideoManager([final_input])\n",
        "    stats_manager = StatsManager()\n",
        "    scene_manager = SceneManager(stats_manager)\n",
        "    scene_manager.add_detector(ContentDetector())\n",
        "    base_timecode = video_manager.get_base_timecode()\n",
        "\n",
        "    video_manager.set_downscale_factor()\n",
        "    video_manager.start()\n",
        "    scene_manager.detect_scenes(frame_source=video_manager)\n",
        "    scene_list = scene_manager.get_scene_list(base_timecode)\n",
        "    video_manager.release()\n",
        "\n",
        "    if not scene_list:\n",
        "        scene_list = [(base_timecode, base_timecode + len(frames) / fps)]\n",
        "    scenes = []\n",
        "    for sc in scene_list:\n",
        "        start_f = sc[0].frame_num\n",
        "        end_f = sc[1].frame_num\n",
        "        scenes.append((start_f, end_f))\n",
        "\n",
        "    # 4) Ball detection\n",
        "    ball_detector = BallDetector(path_ball_track_model, device)\n",
        "    ball_track = ball_detector.infer_model(frames)\n",
        "\n",
        "    # 5) Court detection\n",
        "    court_detector = CourtDetectorNet(path_court_model, device)\n",
        "    homography_matrices, kps_court = court_detector.infer_model(frames)\n",
        "\n",
        "    # 6) Person detection\n",
        "    person_detector = PersonDetector(device)\n",
        "    persons_top, persons_bottom = person_detector.track_players(\n",
        "        frames, homography_matrices, filter_players=False\n",
        "    )\n",
        "\n",
        "    # 7) Bounce detection\n",
        "    bounce_detector = BounceDetector(path_bounce_model)\n",
        "    x_ball = [bp[0] for bp in ball_track]\n",
        "    y_ball = [bp[1] for bp in ball_track]\n",
        "    bounces = bounce_detector.predict(x_ball, y_ball)\n",
        "\n",
        "    # 8) Compose frames & write final videos\n",
        "    print(\"Composing final frames...\")\n",
        "    imgs_res, minimap_frames = main(\n",
        "        frames,\n",
        "        scenes,\n",
        "        bounces,\n",
        "        ball_track,\n",
        "        homography_matrices,\n",
        "        kps_court,\n",
        "        persons_top,\n",
        "        persons_bottom,\n",
        "        draw_trace=True,\n",
        "        trace=7,\n",
        "    )\n",
        "\n",
        "    # Write main video\n",
        "    write(imgs_res, fps, path_output_video)\n",
        "\n",
        "    # Write minimap video\n",
        "    path_minimap_video = \"/content/drive/MyDrive/ASA Tennis Bounds Project/models/court_detection_model/detectron2/post_processing/game2/game2_minimap.mp4\"\n",
        "    write(minimap_frames, fps, path_minimap_video)\n",
        "\n",
        "    # 9) Generate separate heatmaps for bounces/players\n",
        "    generate_minimap_heatmaps(\n",
        "        homography_matrices=homography_matrices,\n",
        "        ball_track=ball_track,\n",
        "        bounces=bounces,\n",
        "        persons_top=persons_top,\n",
        "        persons_bottom=persons_bottom,\n",
        "        output_bounce_heatmap=path_output_bounce_heatmap,\n",
        "        output_player_heatmap=path_output_player_heatmap,\n",
        "        blur_ksize=41,\n",
        "        alpha=0.5,\n",
        "    )\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    print(f\"Done, saved to {path_output_video}. Overall time: {total_time:.2f}s\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "11wkF5_nDDkTFaKCEX-e7doO-I55bn3NW",
      "authorship_tag": "ABX9TyP2P4tqLoDlBBEhQITT71vr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}